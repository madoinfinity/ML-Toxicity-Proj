# ML-Toxicity Classification-Project
This project compared the performance of Naive Bayes, RNNs/LSTMs, and fine-tuned BERT on the Jigsaw Toxic Comment Classification Challenge dataset. It explored both sparse (TF-IDF, CountVectorizer) and dense (GloVe, Word2Vec) text representations, focusing on how data balancing impacts model performance. Naive Bayes with Count Vectors and balanced data gave strong baseline F1 scores, while LSTMs improved results using GloVe embeddings. Ultimately, BERT outperformed all models with ~93% accuracy, showcasing superior contextual understanding, though class-wise F1 scores varied. The study highlighted the trade-offs between model complexity, data balance, and embedding quality.
